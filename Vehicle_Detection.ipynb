{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute color histogram features  \n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "\n",
    "# Define a function to compute binned color features  \n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "\n",
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient = 9, pix_per_cell = 8, cell_per_block = 2, feature_vec=True):\n",
    "\n",
    "    features = []\n",
    "    for channel in range(img.shape[2]):\n",
    "        features.append(hog(img[:,:,channel], orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "               cells_per_block=(cell_per_block, cell_per_block), visualise=False, feature_vector=feature_vec,\n",
    "               block_norm=\"L2-Hys\"))\n",
    "    return np.ravel(features)\n",
    "\n",
    "\n",
    "def calculateFeatures(img):\n",
    "    \n",
    "    features = []\n",
    "    #hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    #hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    \n",
    "    features.append(bin_spatial(img))\n",
    "    #features.append(bin_spatial(hsv))\n",
    "    #features.append(bin_spatial(hls))\n",
    "\n",
    "    #features.append(color_hist(img))\n",
    "    #features.append(color_hist(hsv))\n",
    "    #features.append(color_hist(hls))\n",
    "    \n",
    "    features.append(get_hog_features(img))\n",
    "    #features.append(get_hog_features(hsv))\n",
    "    #features.append(get_hog_features(hls))\n",
    "    \n",
    "    return np.concatenate(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that takes an image,\n",
    "# start and stop positions in both x and y, \n",
    "# window size (x and y dimensions),  \n",
    "# and overlap fraction (for both x and y)\n",
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], window_size = 64, xy_overlap = 0.5):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(window_size * (1 - xy_overlap))\n",
    "    ny_pix_per_step = np.int(window_size * (1 - xy_overlap))\n",
    "    # number of windows in x/y\n",
    "    nx_buffer = np.int(window_size * xy_overlap)\n",
    "    ny_buffer = np.int(window_size * xy_overlap)\n",
    "    nx_windows = np.int((xspan - nx_buffer) / nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan - ny_buffer) / ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs * nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + window_size\n",
    "            starty = ys * ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + window_size\n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = glob.glob('data/vehicles/*/*.png')\n",
    "non_vehicles = glob.glob('data/non-vehicles/*/*.png')\n",
    "\n",
    "car_features = []\n",
    "non_car_features = []\n",
    "for car in vehicles:\n",
    "    img = cv2.imread(car)\n",
    "    car_features.append(calculateFeatures(img))\n",
    "for nocar in non_vehicles:\n",
    "    img = cv2.imread(nocar)\n",
    "    non_car_features.append(calculateFeatures(img))\n",
    "\n",
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, non_car_features)).astype(np.float64)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(non_car_features))))\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rand_state)\n",
    "    \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "# Apply the scaler to X\n",
    "X_train = X_scaler.transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#plt.figure(figsize=(20,20))\n",
    "#plt.subplot(1, 2, 1)\n",
    "#plt.imshow(car)\n",
    "#plt.subplot(1, 2, 2)\n",
    "#plt.imshow(noc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = clf.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
